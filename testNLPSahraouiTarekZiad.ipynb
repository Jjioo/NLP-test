{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "*Q1*"
      ],
      "metadata": {
        "id": "gtOXwkiAHht8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xakn7mmrHOkB",
        "outputId": "3b78db0f-6563-4607-cff0-df991568f5d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word count for 'palestine': 16\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "import fitz\n",
        "import re\n",
        "\n",
        "pdf_file_path = '/content/PALESTINE.pdf'\n",
        "target_word = 'palestine'\n",
        "\n",
        "pdf_document = fitz.open(pdf_file_path)\n",
        "\n",
        "word_count = 0\n",
        "\n",
        "for page_num in range(pdf_document.page_count):\n",
        "    page = pdf_document[page_num]\n",
        "    text = page.get_text()\n",
        "\n",
        "    occurrences = re.findall(r'\\b{}\\b'.format(re.escape(target_word)), text, re.IGNORECASE)\n",
        "\n",
        "    word_count += len(occurrences)\n",
        "\n",
        "pdf_document.close()\n",
        "\n",
        "print(\"Word count for '{}': {}\".format(target_word, word_count))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2**"
      ],
      "metadata": {
        "id": "Lfa_6O5sITCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_document = fitz.open(pdf_file_path)\n",
        "for page_num in range(pdf_document.page_count):\n",
        "    page = pdf_document[page_num]\n",
        "    text = page.get_text()\n",
        "\n",
        "    paragraphs = text.split('\\n')\n",
        "\n",
        "\n",
        "    paragraphs = [p for p in paragraphs if p.strip()]\n",
        "\n",
        "    print(f\"Page {page_num + 1}: {len(paragraphs)} paragraphs\\n\")\n",
        "\n",
        "\n",
        "pdf_document.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68mhq_v0HejJ",
        "outputId": "8aeb8dac-52f9-42ff-d478-5d90153ff70f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page 1: 20 paragraphs\n",
            "\n",
            "Page 2: 42 paragraphs\n",
            "\n",
            "Page 3: 42 paragraphs\n",
            "\n",
            "Page 4: 41 paragraphs\n",
            "\n",
            "Page 5: 35 paragraphs\n",
            "\n",
            "Page 6: 37 paragraphs\n",
            "\n",
            "Page 7: 39 paragraphs\n",
            "\n",
            "Page 8: 38 paragraphs\n",
            "\n",
            "Page 9: 34 paragraphs\n",
            "\n",
            "Page 10: 35 paragraphs\n",
            "\n",
            "Page 11: 33 paragraphs\n",
            "\n",
            "Page 12: 36 paragraphs\n",
            "\n",
            "Page 13: 30 paragraphs\n",
            "\n",
            "Page 14: 37 paragraphs\n",
            "\n",
            "Page 15: 35 paragraphs\n",
            "\n",
            "Page 16: 39 paragraphs\n",
            "\n",
            "Page 17: 37 paragraphs\n",
            "\n",
            "Page 18: 38 paragraphs\n",
            "\n",
            "Page 19: 37 paragraphs\n",
            "\n",
            "Page 20: 38 paragraphs\n",
            "\n",
            "Page 21: 33 paragraphs\n",
            "\n",
            "Page 22: 31 paragraphs\n",
            "\n",
            "Page 23: 35 paragraphs\n",
            "\n",
            "Page 24: 36 paragraphs\n",
            "\n",
            "Page 25: 39 paragraphs\n",
            "\n",
            "Page 26: 3 paragraphs\n",
            "\n",
            "Page 27: 39 paragraphs\n",
            "\n",
            "Page 28: 33 paragraphs\n",
            "\n",
            "Page 29: 34 paragraphs\n",
            "\n",
            "Page 30: 18 paragraphs\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "\n",
        "pdf_document = fitz.open(pdf_file_path)\n",
        "\n",
        "page_num = 0\n",
        "page = pdf_document[page_num]\n",
        "page_text = page.get_text()\n",
        "\n",
        "print(f\"Content of Page 1:\\n{page_text}\")\n",
        "pdf_document.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_usV_XgIVOU",
        "outputId": "4e863658-e774-490a-d540-ebdbc9afbf9b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Content of Page 1:\n",
            " \n",
            "1 \n",
            "PALESTINE \n",
            " \n",
            " \n",
            " \n",
            "Introduction \n",
            " \n",
            "This report assesses the status of Palestinian women ten years after the Beijing Conference in the \n",
            "context of a survey of the Palestinian Authority’s achievements in the critical areas of concern of \n",
            "the Beijing Platform for Action. The report is the outcome of a joint cooperative effort on the \n",
            "part of the Ministry of Women’s Affairs and units concerned with issues of relevance for women \n",
            "in various other ministries. \n",
            " \n",
            "The preparation of this report comes at the time of a significant development in the history of \n",
            "mechanisms for the advancement of Palestinian women, namely the creation of a Ministry of \n",
            "Women’s Affairs within the current Palestinian Government as the main framework for the \n",
            "Government’s ongoing commitment to the empowerment of women and the unification of efforts \n",
            "directed toward that end, to quote from the new Ministry’s official mandate. \n",
            " \n",
            "We hope that this report will contribute to a greater understanding of the economic, social and \n",
            "political status of Palestinian women and will identify current obstacles to their advancement and \n",
            "participation in the development process. We also hope that decision-makers will find it a useful \n",
            "aid to adopting measures and policies aimed at bridging the gender gap. \n",
            " \n",
            "Lastly, we wish to extend our sincere thanks and appreciation to all our women colleagues in \n",
            "units concerned with women’s issues in various ministries for their invaluable assistance in \n",
            "providing us with data and reports on their respective ministries’ activities in this area. \n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "doc = nlp(page_text)\n",
        "\n",
        "# Extract the first sentence\n",
        "first_sentence = next(doc.sents, None)\n",
        "\n",
        "\n",
        "if first_sentence:\n",
        "\n",
        "    print(f\"Original Sentence: {first_sentence.text}\\n\")\n",
        "\n",
        "    # syntactic structure ,first sentence\n",
        "    for token in first_sentence:\n",
        "        print(f\"Token: {token.text}, Dependency: {token.dep_}, Head: {token.head.text}, POS: {token.pos_}, Tag: {token.tag_}\")\n",
        "else:\n",
        "    print(\"No sentences found in the content.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_5mIxgZIqEU",
        "outputId": "d8f128ac-0151-4f24-fc4f-f59ae1480e28"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence:  \n",
            "1 \n",
            "PALESTINE \n",
            " \n",
            " \n",
            " \n",
            "Introduction \n",
            " \n",
            "This report assesses the status of Palestinian women ten years after the Beijing Conference in the \n",
            "context of a survey of the Palestinian Authority’s achievements in the critical areas of concern of \n",
            "the Beijing Platform for Action.\n",
            "\n",
            "Token:  \n",
            ", Dependency: dep, Head: 1, POS: SPACE, Tag: _SP\n",
            "Token: 1, Dependency: nummod, Head: Introduction, POS: NUM, Tag: CD\n",
            "Token: \n",
            ", Dependency: dep, Head: 1, POS: SPACE, Tag: _SP\n",
            "Token: PALESTINE, Dependency: compound, Head: Introduction, POS: PROPN, Tag: NNP\n",
            "Token: \n",
            " \n",
            " \n",
            " \n",
            ", Dependency: dep, Head: PALESTINE, POS: SPACE, Tag: _SP\n",
            "Token: Introduction, Dependency: nsubj, Head: assesses, POS: NOUN, Tag: NN\n",
            "Token: \n",
            " \n",
            ", Dependency: dep, Head: Introduction, POS: SPACE, Tag: _SP\n",
            "Token: This, Dependency: det, Head: report, POS: DET, Tag: DT\n",
            "Token: report, Dependency: nsubj, Head: assesses, POS: NOUN, Tag: NN\n",
            "Token: assesses, Dependency: ROOT, Head: assesses, POS: VERB, Tag: VBZ\n",
            "Token: the, Dependency: det, Head: status, POS: DET, Tag: DT\n",
            "Token: status, Dependency: dobj, Head: assesses, POS: NOUN, Tag: NN\n",
            "Token: of, Dependency: prep, Head: status, POS: ADP, Tag: IN\n",
            "Token: Palestinian, Dependency: amod, Head: women, POS: ADJ, Tag: JJ\n",
            "Token: women, Dependency: pobj, Head: of, POS: NOUN, Tag: NNS\n",
            "Token: ten, Dependency: nummod, Head: years, POS: NUM, Tag: CD\n",
            "Token: years, Dependency: npadvmod, Head: after, POS: NOUN, Tag: NNS\n",
            "Token: after, Dependency: prep, Head: assesses, POS: ADP, Tag: IN\n",
            "Token: the, Dependency: det, Head: Conference, POS: DET, Tag: DT\n",
            "Token: Beijing, Dependency: compound, Head: Conference, POS: PROPN, Tag: NNP\n",
            "Token: Conference, Dependency: pobj, Head: after, POS: PROPN, Tag: NNP\n",
            "Token: in, Dependency: prep, Head: Conference, POS: ADP, Tag: IN\n",
            "Token: the, Dependency: det, Head: context, POS: DET, Tag: DT\n",
            "Token: \n",
            ", Dependency: dep, Head: the, POS: SPACE, Tag: _SP\n",
            "Token: context, Dependency: pobj, Head: in, POS: NOUN, Tag: NN\n",
            "Token: of, Dependency: prep, Head: context, POS: ADP, Tag: IN\n",
            "Token: a, Dependency: det, Head: survey, POS: DET, Tag: DT\n",
            "Token: survey, Dependency: pobj, Head: of, POS: NOUN, Tag: NN\n",
            "Token: of, Dependency: prep, Head: survey, POS: ADP, Tag: IN\n",
            "Token: the, Dependency: det, Head: Authority, POS: DET, Tag: DT\n",
            "Token: Palestinian, Dependency: compound, Head: Authority, POS: PROPN, Tag: NNP\n",
            "Token: Authority, Dependency: poss, Head: achievements, POS: PROPN, Tag: NNP\n",
            "Token: ’s, Dependency: case, Head: Authority, POS: PART, Tag: POS\n",
            "Token: achievements, Dependency: pobj, Head: of, POS: NOUN, Tag: NNS\n",
            "Token: in, Dependency: prep, Head: achievements, POS: ADP, Tag: IN\n",
            "Token: the, Dependency: det, Head: areas, POS: DET, Tag: DT\n",
            "Token: critical, Dependency: amod, Head: areas, POS: ADJ, Tag: JJ\n",
            "Token: areas, Dependency: pobj, Head: in, POS: NOUN, Tag: NNS\n",
            "Token: of, Dependency: prep, Head: areas, POS: ADP, Tag: IN\n",
            "Token: concern, Dependency: pobj, Head: of, POS: NOUN, Tag: NN\n",
            "Token: of, Dependency: prep, Head: concern, POS: ADP, Tag: IN\n",
            "Token: \n",
            ", Dependency: dep, Head: of, POS: SPACE, Tag: _SP\n",
            "Token: the, Dependency: det, Head: Platform, POS: DET, Tag: DT\n",
            "Token: Beijing, Dependency: compound, Head: Platform, POS: PROPN, Tag: NNP\n",
            "Token: Platform, Dependency: pobj, Head: of, POS: PROPN, Tag: NNP\n",
            "Token: for, Dependency: prep, Head: Platform, POS: ADP, Tag: IN\n",
            "Token: Action, Dependency: pobj, Head: for, POS: PROPN, Tag: NNP\n",
            "Token: ., Dependency: punct, Head: assesses, POS: PUNCT, Tag: .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5**"
      ],
      "metadata": {
        "id": "PEYJOLzhL6X6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_document = fitz.open(pdf_file_path)\n",
        "\n",
        "# tokenize the text kol paga\n",
        "for page_num in range(pdf_document.page_count):\n",
        "\n",
        "    page = pdf_document[page_num]\n",
        "    text = page.get_text()\n",
        "\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # number of words\n",
        "    word_count = sum(1 for token in doc if token.is_alpha)\n",
        "\n",
        "    print(f\"Page {page_num + 1}: {word_count} words\")\n",
        "\n",
        "pdf_document.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRhj2F_wLnz5",
        "outputId": "20d399d3-4e7f-4fe3-c0bb-f4b9108c7a7a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page 1: 241 words\n",
            "Page 2: 559 words\n",
            "Page 3: 534 words\n",
            "Page 4: 491 words\n",
            "Page 5: 464 words\n",
            "Page 6: 449 words\n",
            "Page 7: 511 words\n",
            "Page 8: 512 words\n",
            "Page 9: 376 words\n",
            "Page 10: 424 words\n",
            "Page 11: 352 words\n",
            "Page 12: 450 words\n",
            "Page 13: 314 words\n",
            "Page 14: 415 words\n",
            "Page 15: 367 words\n",
            "Page 16: 363 words\n",
            "Page 17: 437 words\n",
            "Page 18: 373 words\n",
            "Page 19: 476 words\n",
            "Page 20: 497 words\n",
            "Page 21: 326 words\n",
            "Page 22: 336 words\n",
            "Page 23: 428 words\n",
            "Page 24: 422 words\n",
            "Page 25: 494 words\n",
            "Page 26: 30 words\n",
            "Page 27: 474 words\n",
            "Page 28: 356 words\n",
            "Page 29: 354 words\n",
            "Page 30: 150 words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6**"
      ],
      "metadata": {
        "id": "xsG99qoPMG3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_document = fitz.open(pdf_file_path)\n",
        "\n",
        "# text of Page 1\n",
        "page_num = 0  # Assuming you want to process Page 1\n",
        "page = pdf_document[page_num]\n",
        "text = page.get_text()\n",
        "\n",
        "# Process the text using spaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Eliminate stop words\n",
        "filtered_words = [token.text for token in doc if not token.is_stop]\n",
        "filtered_text = ' '.join(filtered_words)\n",
        "word_count = len(filtered_words)\n",
        "print(f\"Number of words in the filtered text: {word_count}\")\n",
        "\n",
        "\n",
        "pdf_document.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLDeM8YEMbDJ",
        "outputId": "eee595c0-e70c-4ac8-d2d9-deb52d3a9947"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in the filtered text: 156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Text Cleaning Q7"
      ],
      "metadata": {
        "id": "2sl9BF00NZys"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load the spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Open the PDF document\n",
        "pdf_document = fitz.open(pdf_file_path)\n",
        "\n",
        "# Get the text of Page 1\n",
        "page_num = 0  # Assuming you want to process Page 1\n",
        "page = pdf_document[page_num]\n",
        "text = page.get_text()\n",
        "\n",
        "# Process the text using spaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Eliminate stop words and print the remaining words\n",
        "filtered_words = [token.text for token in doc if not token.is_stop]\n",
        "filtered_text = ' '.join(filtered_words)\n",
        "\n",
        "# Count the number of words in the filtered text\n",
        "word_count = len(filtered_words)\n",
        "\n",
        "# Print the text without stop words\n",
        "print(f\"Text of Page 1 without stop words:\\n{filtered_text}\")\n",
        "\n",
        "# Print the number of words\n",
        "print(f\"Number of words in the filtered text: {word_count}\")\n",
        "\n",
        "# Close the PDF document\n",
        "pdf_document.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUOfrl6xOkGy",
        "outputId": "73fd4ff7-02da-4d70-f27e-f055dcb88591"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text of Page 1 without stop words:\n",
            " \n",
            " 1 \n",
            " PALESTINE \n",
            " \n",
            " \n",
            " \n",
            " Introduction \n",
            " \n",
            " report assesses status Palestinian women years Beijing Conference \n",
            " context survey Palestinian Authority achievements critical areas concern \n",
            " Beijing Platform Action . report outcome joint cooperative effort \n",
            " Ministry Women Affairs units concerned issues relevance women \n",
            " ministries . \n",
            " \n",
            " preparation report comes time significant development history \n",
            " mechanisms advancement Palestinian women , creation Ministry \n",
            " Women Affairs current Palestinian Government main framework \n",
            " Government ongoing commitment empowerment women unification efforts \n",
            " directed end , quote new Ministry official mandate . \n",
            " \n",
            " hope report contribute greater understanding economic , social \n",
            " political status Palestinian women identify current obstacles advancement \n",
            " participation development process . hope decision - makers find useful \n",
            " aid adopting measures policies aimed bridging gender gap . \n",
            " \n",
            " Lastly , wish extend sincere thanks appreciation women colleagues \n",
            " units concerned women issues ministries invaluable assistance \n",
            " providing data reports respective ministries ’ activities area . \n",
            " \n",
            "\n",
            "Number of words in the filtered text: 156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7**"
      ],
      "metadata": {
        "id": "ds0yCd4EQkPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk import pos_tag\n",
        "\n",
        "# Sample text\n",
        "text = \"\"\"\n",
        "PALESTINE\n",
        "\n",
        "Introduction\n",
        "\n",
        "This report assesses the status of Palestinian women years after the Beijing Conference\n",
        "in the context of the survey of Palestinian Authority achievements in critical areas of concern\n",
        "outlined in the Beijing Platform for Action. The report is the outcome of a joint cooperative effort\n",
        "between the Ministry of Women Affairs and units concerned with issues relevant to women in various\n",
        "ministries.\n",
        "\n",
        "The preparation of this report comes at a significant point in the development history\n",
        "of mechanisms for the advancement of Palestinian women, with the creation of the Ministry\n",
        "of Women Affairs under the current Palestinian Government. It is the main framework for the\n",
        "Government's ongoing commitment to the empowerment of women and unification efforts\n",
        "directed towards this end, as stated in the new Ministry's official mandate.\n",
        "\n",
        "We hope that this report contributes to a greater understanding of the economic, social,\n",
        "and political status of Palestinian women, and helps identify current obstacles to their advancement\n",
        "and participation in the development process. We also hope that decision-makers find it useful\n",
        "in adopting measures and policies aimed at bridging the gender gap.\n",
        "\n",
        "Lastly, we wish to extend our sincere thanks and appreciation to our women colleagues\n",
        "in the units concerned with women's issues in various ministries for their invaluable assistance\n",
        "in providing data and reports on their respective ministries' activities in this area.\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Perform POS tagging\n",
        "pos_tags = pos_tag(tokens)\n",
        "\n",
        "# Print the POS tags\n",
        "for tag in pos_tags:\n",
        "    print(tag)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "affIB8Y0PZzV",
        "outputId": "d377dccf-b0be-46e8-ce25-ad345cb0a355"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('PALESTINE', 'NNP')\n",
            "('Introduction', 'NNP')\n",
            "('This', 'DT')\n",
            "('report', 'NN')\n",
            "('assesses', 'VBZ')\n",
            "('the', 'DT')\n",
            "('status', 'NN')\n",
            "('of', 'IN')\n",
            "('Palestinian', 'JJ')\n",
            "('women', 'NNS')\n",
            "('years', 'NNS')\n",
            "('after', 'IN')\n",
            "('the', 'DT')\n",
            "('Beijing', 'NNP')\n",
            "('Conference', 'NNP')\n",
            "('in', 'IN')\n",
            "('the', 'DT')\n",
            "('context', 'NN')\n",
            "('of', 'IN')\n",
            "('the', 'DT')\n",
            "('survey', 'NN')\n",
            "('of', 'IN')\n",
            "('Palestinian', 'JJ')\n",
            "('Authority', 'NNP')\n",
            "('achievements', 'NNS')\n",
            "('in', 'IN')\n",
            "('critical', 'JJ')\n",
            "('areas', 'NNS')\n",
            "('of', 'IN')\n",
            "('concern', 'NN')\n",
            "('outlined', 'VBN')\n",
            "('in', 'IN')\n",
            "('the', 'DT')\n",
            "('Beijing', 'NNP')\n",
            "('Platform', 'NNP')\n",
            "('for', 'IN')\n",
            "('Action', 'NNP')\n",
            "('.', '.')\n",
            "('The', 'DT')\n",
            "('report', 'NN')\n",
            "('is', 'VBZ')\n",
            "('the', 'DT')\n",
            "('outcome', 'NN')\n",
            "('of', 'IN')\n",
            "('a', 'DT')\n",
            "('joint', 'JJ')\n",
            "('cooperative', 'JJ')\n",
            "('effort', 'NN')\n",
            "('between', 'IN')\n",
            "('the', 'DT')\n",
            "('Ministry', 'NNP')\n",
            "('of', 'IN')\n",
            "('Women', 'NNP')\n",
            "('Affairs', 'NNPS')\n",
            "('and', 'CC')\n",
            "('units', 'NNS')\n",
            "('concerned', 'VBN')\n",
            "('with', 'IN')\n",
            "('issues', 'NNS')\n",
            "('relevant', 'VBP')\n",
            "('to', 'TO')\n",
            "('women', 'NNS')\n",
            "('in', 'IN')\n",
            "('various', 'JJ')\n",
            "('ministries', 'NNS')\n",
            "('.', '.')\n",
            "('The', 'DT')\n",
            "('preparation', 'NN')\n",
            "('of', 'IN')\n",
            "('this', 'DT')\n",
            "('report', 'NN')\n",
            "('comes', 'VBZ')\n",
            "('at', 'IN')\n",
            "('a', 'DT')\n",
            "('significant', 'JJ')\n",
            "('point', 'NN')\n",
            "('in', 'IN')\n",
            "('the', 'DT')\n",
            "('development', 'NN')\n",
            "('history', 'NN')\n",
            "('of', 'IN')\n",
            "('mechanisms', 'NN')\n",
            "('for', 'IN')\n",
            "('the', 'DT')\n",
            "('advancement', 'NN')\n",
            "('of', 'IN')\n",
            "('Palestinian', 'JJ')\n",
            "('women', 'NNS')\n",
            "(',', ',')\n",
            "('with', 'IN')\n",
            "('the', 'DT')\n",
            "('creation', 'NN')\n",
            "('of', 'IN')\n",
            "('the', 'DT')\n",
            "('Ministry', 'NNP')\n",
            "('of', 'IN')\n",
            "('Women', 'NNP')\n",
            "('Affairs', 'NNPS')\n",
            "('under', 'IN')\n",
            "('the', 'DT')\n",
            "('current', 'JJ')\n",
            "('Palestinian', 'JJ')\n",
            "('Government', 'NN')\n",
            "('.', '.')\n",
            "('It', 'PRP')\n",
            "('is', 'VBZ')\n",
            "('the', 'DT')\n",
            "('main', 'JJ')\n",
            "('framework', 'NN')\n",
            "('for', 'IN')\n",
            "('the', 'DT')\n",
            "('Government', 'NNP')\n",
            "(\"'s\", 'POS')\n",
            "('ongoing', 'JJ')\n",
            "('commitment', 'NN')\n",
            "('to', 'TO')\n",
            "('the', 'DT')\n",
            "('empowerment', 'NN')\n",
            "('of', 'IN')\n",
            "('women', 'NNS')\n",
            "('and', 'CC')\n",
            "('unification', 'NN')\n",
            "('efforts', 'NNS')\n",
            "('directed', 'VBD')\n",
            "('towards', 'NNS')\n",
            "('this', 'DT')\n",
            "('end', 'NN')\n",
            "(',', ',')\n",
            "('as', 'IN')\n",
            "('stated', 'VBN')\n",
            "('in', 'IN')\n",
            "('the', 'DT')\n",
            "('new', 'JJ')\n",
            "('Ministry', 'NNP')\n",
            "(\"'s\", 'POS')\n",
            "('official', 'JJ')\n",
            "('mandate', 'NN')\n",
            "('.', '.')\n",
            "('We', 'PRP')\n",
            "('hope', 'VBP')\n",
            "('that', 'IN')\n",
            "('this', 'DT')\n",
            "('report', 'NN')\n",
            "('contributes', 'VBZ')\n",
            "('to', 'TO')\n",
            "('a', 'DT')\n",
            "('greater', 'JJR')\n",
            "('understanding', 'NN')\n",
            "('of', 'IN')\n",
            "('the', 'DT')\n",
            "('economic', 'JJ')\n",
            "(',', ',')\n",
            "('social', 'JJ')\n",
            "(',', ',')\n",
            "('and', 'CC')\n",
            "('political', 'JJ')\n",
            "('status', 'NN')\n",
            "('of', 'IN')\n",
            "('Palestinian', 'JJ')\n",
            "('women', 'NNS')\n",
            "(',', ',')\n",
            "('and', 'CC')\n",
            "('helps', 'VBZ')\n",
            "('identify', 'VB')\n",
            "('current', 'JJ')\n",
            "('obstacles', 'NNS')\n",
            "('to', 'TO')\n",
            "('their', 'PRP$')\n",
            "('advancement', 'NN')\n",
            "('and', 'CC')\n",
            "('participation', 'NN')\n",
            "('in', 'IN')\n",
            "('the', 'DT')\n",
            "('development', 'NN')\n",
            "('process', 'NN')\n",
            "('.', '.')\n",
            "('We', 'PRP')\n",
            "('also', 'RB')\n",
            "('hope', 'VBP')\n",
            "('that', 'IN')\n",
            "('decision-makers', 'NNS')\n",
            "('find', 'VBP')\n",
            "('it', 'PRP')\n",
            "('useful', 'JJ')\n",
            "('in', 'IN')\n",
            "('adopting', 'VBG')\n",
            "('measures', 'NNS')\n",
            "('and', 'CC')\n",
            "('policies', 'NNS')\n",
            "('aimed', 'VBN')\n",
            "('at', 'IN')\n",
            "('bridging', 'VBG')\n",
            "('the', 'DT')\n",
            "('gender', 'NN')\n",
            "('gap', 'NN')\n",
            "('.', '.')\n",
            "('Lastly', 'RB')\n",
            "(',', ',')\n",
            "('we', 'PRP')\n",
            "('wish', 'VBP')\n",
            "('to', 'TO')\n",
            "('extend', 'VB')\n",
            "('our', 'PRP$')\n",
            "('sincere', 'JJ')\n",
            "('thanks', 'NNS')\n",
            "('and', 'CC')\n",
            "('appreciation', 'NN')\n",
            "('to', 'TO')\n",
            "('our', 'PRP$')\n",
            "('women', 'NNS')\n",
            "('colleagues', 'NNS')\n",
            "('in', 'IN')\n",
            "('the', 'DT')\n",
            "('units', 'NNS')\n",
            "('concerned', 'VBN')\n",
            "('with', 'IN')\n",
            "('women', 'NNS')\n",
            "(\"'s\", 'POS')\n",
            "('issues', 'NNS')\n",
            "('in', 'IN')\n",
            "('various', 'JJ')\n",
            "('ministries', 'NNS')\n",
            "('for', 'IN')\n",
            "('their', 'PRP$')\n",
            "('invaluable', 'JJ')\n",
            "('assistance', 'NN')\n",
            "('in', 'IN')\n",
            "('providing', 'VBG')\n",
            "('data', 'NNS')\n",
            "('and', 'CC')\n",
            "('reports', 'NNS')\n",
            "('on', 'IN')\n",
            "('their', 'PRP$')\n",
            "('respective', 'JJ')\n",
            "('ministries', 'NNS')\n",
            "(\"'\", 'POS')\n",
            "('activities', 'NNS')\n",
            "('in', 'IN')\n",
            "('this', 'DT')\n",
            "('area', 'NN')\n",
            "('.', '.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q8**"
      ],
      "metadata": {
        "id": "r2B-eG3hQ73q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "pdf_document = fitz.open(pdf_file_path)\n",
        "\n",
        "# text of Page 1\n",
        "page_num = 0  # Assuming you want to process Page 1\n",
        "page = pdf_document[page_num]\n",
        "text = page.get_text()\n",
        "\n",
        "paragraphs = [p for p in text.split('\\n') if p.strip()]\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# BOW model\n",
        "bow_matrix = vectorizer.fit_transform(paragraphs)\n",
        "\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# BOW matrix\n",
        "print(\"Bag-of-Words Matrix:\")\n",
        "print(bow_matrix.toarray())\n",
        "print(\"\\nFeature Names:\")\n",
        "print(feature_names)\n",
        "\n",
        "# Close the PDF document\n",
        "pdf_document.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpU_ZWSQQHkZ",
        "outputId": "0ed3b94e-722e-4a55-d845-a0bf32bcc0d3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag-of-Words Matrix:\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 1 0]\n",
            " [0 0 0 ... 0 1 0]\n",
            " [0 0 1 ... 0 0 0]]\n",
            "\n",
            "Feature Names:\n",
            "['achievements' 'action' 'activities' 'adopting' 'advancement' 'affairs'\n",
            " 'after' 'aid' 'aimed' 'all' 'also' 'and' 'appreciation' 'area' 'areas'\n",
            " 'as' 'assesses' 'assistance' 'at' 'authority' 'beijing' 'bridging'\n",
            " 'colleagues' 'comes' 'commitment' 'concern' 'concerned' 'conference'\n",
            " 'context' 'contribute' 'cooperative' 'creation' 'critical' 'current'\n",
            " 'data' 'decision' 'development' 'directed' 'economic' 'effort' 'efforts'\n",
            " 'empowerment' 'end' 'extend' 'find' 'for' 'framework' 'from' 'gap'\n",
            " 'gender' 'government' 'greater' 'history' 'hope' 'identify' 'in'\n",
            " 'introduction' 'invaluable' 'is' 'issues' 'it' 'joint' 'lastly' 'main'\n",
            " 'makers' 'mandate' 'measures' 'mechanisms' 'ministries' 'ministry'\n",
            " 'namely' 'new' 'obstacles' 'of' 'official' 'on' 'ongoing' 'other' 'our'\n",
            " 'outcome' 'palestine' 'palestinian' 'part' 'participation' 'platform'\n",
            " 'policies' 'political' 'preparation' 'process' 'providing' 'quote'\n",
            " 'relevance' 'report' 'reports' 'respective' 'significant' 'sincere'\n",
            " 'social' 'status' 'survey' 'ten' 'thanks' 'that' 'the' 'their' 'this'\n",
            " 'time' 'to' 'toward' 'understanding' 'unification' 'units' 'us' 'useful'\n",
            " 'various' 'we' 'will' 'wish' 'with' 'within' 'women' 'years']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q9**"
      ],
      "metadata": {
        "id": "yH35HTeQRU55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "# Split the text into paragraphs based on newline character\n",
        "paragraphs = [p for p in text.split('\\n') if p.strip()]\n",
        "\n",
        "# Initialize the TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Apply the TF-IDF model to the paragraphs\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(paragraphs)\n",
        "\n",
        "# Get the feature names (words) in the TF-IDF model\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Print the TF-IDF matrix and feature names\n",
        "print(\"TF-IDF Matrix:\")\n",
        "print(tfidf_matrix.toarray())\n",
        "print(\"\\nFeature Names:\")\n",
        "print(feature_names)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6R4dEBnQ-61",
        "outputId": "20af7104-69ad-42a7-ec94-3d4098507150"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Matrix:\n",
            "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.         0.1416188  0.        ]\n",
            " [0.         0.         0.         ... 0.         0.18425777 0.        ]\n",
            " [0.         0.         0.30378974 ... 0.         0.         0.        ]]\n",
            "\n",
            "Feature Names:\n",
            "['achievements' 'action' 'activities' 'adopting' 'advancement' 'affairs'\n",
            " 'after' 'aid' 'aimed' 'all' 'also' 'and' 'appreciation' 'area' 'areas'\n",
            " 'as' 'assesses' 'assistance' 'at' 'authority' 'beijing' 'bridging'\n",
            " 'colleagues' 'comes' 'commitment' 'concern' 'concerned' 'conference'\n",
            " 'context' 'contribute' 'cooperative' 'creation' 'critical' 'current'\n",
            " 'data' 'decision' 'development' 'directed' 'economic' 'effort' 'efforts'\n",
            " 'empowerment' 'end' 'extend' 'find' 'for' 'framework' 'from' 'gap'\n",
            " 'gender' 'government' 'greater' 'history' 'hope' 'identify' 'in'\n",
            " 'introduction' 'invaluable' 'is' 'issues' 'it' 'joint' 'lastly' 'main'\n",
            " 'makers' 'mandate' 'measures' 'mechanisms' 'ministries' 'ministry'\n",
            " 'namely' 'new' 'obstacles' 'of' 'official' 'on' 'ongoing' 'other' 'our'\n",
            " 'outcome' 'palestine' 'palestinian' 'part' 'participation' 'platform'\n",
            " 'policies' 'political' 'preparation' 'process' 'providing' 'quote'\n",
            " 'relevance' 'report' 'reports' 'respective' 'significant' 'sincere'\n",
            " 'social' 'status' 'survey' 'ten' 'thanks' 'that' 'the' 'their' 'this'\n",
            " 'time' 'to' 'toward' 'understanding' 'unification' 'units' 'us' 'useful'\n",
            " 'various' 'we' 'will' 'wish' 'with' 'within' 'women' 'years']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q10**\n",
        "im using colab .. the size of glove is so large ..so i use the tf-idf"
      ],
      "metadata": {
        "id": "27goRbAKRzv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Get the feature names (words) in the TF-IDF model\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Dictionary to store similar words for each word in the TF-IDF model\n",
        "similar_words_dict = {}\n",
        "\n",
        "# Find similar words for each word in the TF-IDF model\n",
        "for word in feature_names:\n",
        "    token = nlp(word)\n",
        "\n",
        "    # Check if the word is in the spaCy vocabulary\n",
        "    if token.has_vector:\n",
        "        # Use spaCy's most_similar method to get similar words\n",
        "        similar_words = [w for w in feature_names if w != word and cosine_similarity(tfidf_matrix[:, tfidf_vectorizer.vocabulary_[word]].reshape(1, -1), tfidf_matrix[:, tfidf_vectorizer.vocabulary_[w]].reshape(1, -1))[0][0] > 0.5]\n",
        "\n",
        "        # Store similar words in the dictionary\n",
        "        similar_words_dict[word] = similar_words\n",
        "\n",
        "# Print similar words for each word in the TF-IDF model\n",
        "for word, similar_words in similar_words_dict.items():\n",
        "    print(f\"Similar words for '{word}': {', '.join(similar_words)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_AdXAcERcxa",
        "outputId": "ae92254f-a797-40f5-c06e-1dd77707a8ac"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similar words for 'achievements': areas, authority, concern, context, critical, of, survey\n",
            "Similar words for 'action': beijing, cooperative, effort, is, joint, on, outcome, platform\n",
            "Similar words for 'activities': area, data, on, providing, reports, respective, their, us, with\n",
            "Similar words for 'adopting': aid, aimed, at, bridging, gap, gender, measures, policies\n",
            "Similar words for 'advancement': creation, identify, mechanisms, namely, obstacles, palestinian, political, status\n",
            "Similar words for 'affairs': as, current, for, framework, government, main, part, relevance, within, women\n",
            "Similar words for 'after': assesses, beijing, conference, report, status, ten, this, years\n",
            "Similar words for 'aid': adopting, aimed, at, bridging, gap, gender, measures, policies\n",
            "Similar words for 'aimed': adopting, aid, at, bridging, gap, gender, measures, policies\n",
            "Similar words for 'all': appreciation, colleagues, extend, lastly, our, sincere, thanks, to, we, wish\n",
            "Similar words for 'also': decision, development, find, hope, it, makers, participation, process, that, useful, we, will\n",
            "Similar words for 'and': identify, obstacles, political, their, to, will, women\n",
            "Similar words for 'appreciation': all, colleagues, extend, lastly, our, sincere, thanks, to, we, wish\n",
            "Similar words for 'area': activities, data, on, providing, reports, respective, their, us, with\n",
            "Similar words for 'areas': achievements, authority, concern, context, critical, of, survey\n",
            "Similar words for 'as': affairs, current, framework, government, main, within\n",
            "Similar words for 'assesses': after, beijing, conference, report, status, ten, this, years\n",
            "Similar words for 'assistance': concerned, in, invaluable, issues, their, units, with\n",
            "Similar words for 'at': adopting, aid, aimed, bridging, comes, gap, gender, history, measures, policies, preparation, significant, time\n",
            "Similar words for 'authority': achievements, areas, concern, context, critical, of, survey\n",
            "Similar words for 'beijing': action, after, assesses, conference, cooperative, effort, is, joint, outcome, platform, report, status, ten, the, years\n",
            "Similar words for 'bridging': adopting, aid, aimed, at, gap, gender, measures, policies\n",
            "Similar words for 'colleagues': all, appreciation, extend, lastly, our, sincere, thanks, to, we, wish\n",
            "Similar words for 'comes': at, development, history, preparation, significant, time\n",
            "Similar words for 'commitment': efforts, empowerment, government, ongoing, unification\n",
            "Similar words for 'concern': achievements, areas, authority, context, critical, of, survey\n",
            "Similar words for 'concerned': assistance, for, invaluable, issues, part, relevance, units, with, women\n",
            "Similar words for 'conference': after, assesses, beijing, report, status, ten, this, years\n",
            "Similar words for 'context': achievements, areas, authority, concern, critical, of, survey\n",
            "Similar words for 'contribute': economic, greater, hope, report, social, that, this, understanding, we, will\n",
            "Similar words for 'cooperative': action, beijing, effort, is, joint, on, outcome, platform\n",
            "Similar words for 'creation': advancement, mechanisms, ministry, namely\n",
            "Similar words for 'critical': achievements, areas, authority, concern, context, of, survey\n",
            "Similar words for 'current': affairs, as, framework, identify, main, obstacles, palestinian, political, status, within\n",
            "Similar words for 'data': activities, area, on, providing, reports, respective, their, us, with\n",
            "Similar words for 'decision': also, development, find, hope, it, makers, participation, process, that, useful, we, will\n",
            "Similar words for 'development': also, comes, decision, find, history, it, makers, participation, preparation, process, significant, time, useful\n",
            "Similar words for 'directed': end, from, mandate, ministry, new, official, quote, that, toward\n",
            "Similar words for 'economic': contribute, greater, hope, report, social, that, this, understanding, we, will\n",
            "Similar words for 'effort': action, beijing, cooperative, is, joint, on, outcome, platform\n",
            "Similar words for 'efforts': commitment, empowerment, government, ongoing, unification\n",
            "Similar words for 'empowerment': commitment, efforts, government, ongoing, unification\n",
            "Similar words for 'end': directed, from, mandate, ministry, new, official, quote, that, toward\n",
            "Similar words for 'extend': all, appreciation, colleagues, lastly, our, sincere, thanks, to, we, wish\n",
            "Similar words for 'find': also, decision, development, hope, it, makers, participation, process, that, useful, we, will\n",
            "Similar words for 'for': affairs, concerned, issues, ministry, the, units, with, women\n",
            "Similar words for 'framework': affairs, as, current, government, main, within\n",
            "Similar words for 'from': directed, end, mandate, ministry, new, official, quote, that, toward\n",
            "Similar words for 'gap': adopting, aid, aimed, at, bridging, gender, measures, policies\n",
            "Similar words for 'gender': adopting, aid, aimed, at, bridging, gap, measures, policies\n",
            "Similar words for 'government': affairs, as, commitment, efforts, empowerment, framework, main, ongoing, unification, within\n",
            "Similar words for 'greater': contribute, economic, hope, report, social, that, this, understanding, we, will\n",
            "Similar words for 'history': at, comes, development, preparation, significant, time\n",
            "Similar words for 'hope': also, contribute, decision, economic, find, greater, it, makers, participation, process, social, that, understanding, useful, we, will\n",
            "Similar words for 'identify': advancement, and, current, obstacles, political, status, their, will\n",
            "Similar words for 'in': assistance, invaluable, ministries, other, various, with\n",
            "Similar words for 'introduction': \n",
            "Similar words for 'invaluable': assistance, concerned, in, issues, their, units, with\n",
            "Similar words for 'is': action, beijing, cooperative, effort, joint, on, outcome, platform\n",
            "Similar words for 'issues': assistance, concerned, for, invaluable, part, relevance, units, with, women\n",
            "Similar words for 'it': also, decision, development, find, hope, makers, participation, process, that, useful, we, will\n",
            "Similar words for 'joint': action, beijing, cooperative, effort, is, on, outcome, platform\n",
            "Similar words for 'lastly': all, appreciation, colleagues, extend, our, sincere, thanks, to, we, wish\n",
            "Similar words for 'main': affairs, as, current, framework, government, within\n",
            "Similar words for 'makers': also, decision, development, find, hope, it, participation, process, that, useful, we, will\n",
            "Similar words for 'mandate': directed, end, from, ministry, new, official, quote, that, toward\n",
            "Similar words for 'measures': adopting, aid, aimed, at, bridging, gap, gender, policies\n",
            "Similar words for 'mechanisms': advancement, creation, ministry, namely\n",
            "Similar words for 'ministries': in, other, various\n",
            "Similar words for 'ministry': creation, directed, end, for, from, mandate, mechanisms, namely, new, of, official, part, quote, relevance, toward, women\n",
            "Similar words for 'namely': advancement, creation, mechanisms, ministry\n",
            "Similar words for 'new': directed, end, from, mandate, ministry, official, quote, that, toward\n",
            "Similar words for 'obstacles': advancement, and, current, identify, political, status, their, will\n",
            "Similar words for 'of': achievements, areas, authority, concern, context, critical, ministry, palestinian, survey, the, women\n",
            "Similar words for 'official': directed, end, from, mandate, ministry, new, quote, that, toward\n",
            "Similar words for 'on': action, activities, area, cooperative, data, effort, is, joint, outcome, platform, providing, reports, respective, us\n",
            "Similar words for 'ongoing': commitment, efforts, empowerment, government, unification\n",
            "Similar words for 'other': in, ministries, various\n",
            "Similar words for 'our': all, appreciation, colleagues, extend, lastly, sincere, thanks, to, we, wish\n",
            "Similar words for 'outcome': action, beijing, cooperative, effort, is, joint, on, platform\n",
            "Similar words for 'palestine': \n",
            "Similar words for 'palestinian': advancement, current, of, status, the, women\n",
            "Similar words for 'part': affairs, concerned, issues, ministry, relevance, units, with, women\n",
            "Similar words for 'participation': also, decision, development, find, hope, it, makers, process, that, useful, we, will\n",
            "Similar words for 'platform': action, beijing, cooperative, effort, is, joint, on, outcome\n",
            "Similar words for 'policies': adopting, aid, aimed, at, bridging, gap, gender, measures\n",
            "Similar words for 'political': advancement, and, current, identify, obstacles, status, their, will\n",
            "Similar words for 'preparation': at, comes, development, history, significant, time\n",
            "Similar words for 'process': also, decision, development, find, hope, it, makers, participation, that, useful, we, will\n",
            "Similar words for 'providing': activities, area, data, on, reports, respective, their, us, with\n",
            "Similar words for 'quote': directed, end, from, mandate, ministry, new, official, that, toward\n",
            "Similar words for 'relevance': affairs, concerned, issues, ministry, part, units, with, women\n",
            "Similar words for 'report': after, assesses, beijing, conference, contribute, economic, greater, social, ten, the, this, understanding, years\n",
            "Similar words for 'reports': activities, area, data, on, providing, respective, their, us, with\n",
            "Similar words for 'respective': activities, area, data, on, providing, reports, their, us, with\n",
            "Similar words for 'significant': at, comes, development, history, preparation, time\n",
            "Similar words for 'sincere': all, appreciation, colleagues, extend, lastly, our, thanks, to, we, wish\n",
            "Similar words for 'social': contribute, economic, greater, hope, report, that, this, understanding, we, will\n",
            "Similar words for 'status': advancement, after, assesses, beijing, conference, current, identify, obstacles, palestinian, political, ten, years\n",
            "Similar words for 'survey': achievements, areas, authority, concern, context, critical, of\n",
            "Similar words for 'ten': after, assesses, beijing, conference, report, status, this, years\n",
            "Similar words for 'thanks': all, appreciation, colleagues, extend, lastly, our, sincere, to, we, wish\n",
            "Similar words for 'that': also, contribute, decision, directed, economic, end, find, from, greater, hope, it, makers, mandate, new, official, participation, process, quote, social, toward, understanding, useful, we, will\n",
            "Similar words for 'the': beijing, for, of, palestinian, report, women\n",
            "Similar words for 'their': activities, and, area, assistance, data, identify, invaluable, obstacles, political, providing, reports, respective, us, with\n",
            "Similar words for 'this': after, assesses, conference, contribute, economic, greater, report, social, ten, understanding, years\n",
            "Similar words for 'time': at, comes, development, history, preparation, significant\n",
            "Similar words for 'to': all, and, appreciation, colleagues, extend, lastly, our, sincere, thanks, we, wish\n",
            "Similar words for 'toward': directed, end, from, mandate, ministry, new, official, quote, that\n",
            "Similar words for 'understanding': contribute, economic, greater, hope, report, social, that, this, we, will\n",
            "Similar words for 'unification': commitment, efforts, empowerment, government, ongoing\n",
            "Similar words for 'units': assistance, concerned, for, invaluable, issues, part, relevance, with, women\n",
            "Similar words for 'us': activities, area, data, on, providing, reports, respective, their, with\n",
            "Similar words for 'useful': also, decision, development, find, hope, it, makers, participation, process, that, we, will\n",
            "Similar words for 'various': in, ministries, other\n",
            "Similar words for 'we': all, also, appreciation, colleagues, contribute, decision, economic, extend, find, greater, hope, it, lastly, makers, our, participation, process, sincere, social, thanks, that, to, understanding, useful, will, wish\n",
            "Similar words for 'will': also, and, contribute, decision, economic, find, greater, hope, identify, it, makers, obstacles, participation, political, process, social, that, understanding, useful, we\n",
            "Similar words for 'wish': all, appreciation, colleagues, extend, lastly, our, sincere, thanks, to, we\n",
            "Similar words for 'with': activities, area, assistance, concerned, data, for, in, invaluable, issues, part, providing, relevance, reports, respective, their, units, us, women\n",
            "Similar words for 'within': affairs, as, current, framework, government, main\n",
            "Similar words for 'women': affairs, and, concerned, for, issues, ministry, of, palestinian, part, relevance, the, units, with\n",
            "Similar words for 'years': after, assesses, beijing, conference, report, status, ten, this\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WiBj993iR3vj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}